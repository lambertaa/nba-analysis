{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge draft datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "draftnet_f = '../data/nbadraft_strengths_weaknesses.csv'\n",
    "alltimedraft_f = '../data/alltime_draft.csv'\n",
    "\n",
    "draftnet_df = pd.read_csv(draftnet_f)\n",
    "alltimedraft_df = pd.read_csv(alltimedraft_f)\n",
    "\n",
    "# for getting a column to join on\n",
    "alltimedraft_df['player'] = alltimedraft_df.PLAYER_NAME.str.lower().str.replace(' ','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>player</th>\n",
       "      <th>season</th>\n",
       "      <th>strengths</th>\n",
       "      <th>weaknesses</th>\n",
       "      <th>overall</th>\n",
       "      <th>Athleticism</th>\n",
       "      <th>Size</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Strength</th>\n",
       "      <th>Quickness</th>\n",
       "      <th>Leadership</th>\n",
       "      <th>JumpShot</th>\n",
       "      <th>NBAReady</th>\n",
       "      <th>Rebounding</th>\n",
       "      <th>Potential</th>\n",
       "      <th>PostSkills</th>\n",
       "      <th>Intangibles</th>\n",
       "      <th>BallHandling</th>\n",
       "      <th>Passing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1631094</td>\n",
       "      <td>Paolo Banchero</td>\n",
       "      <td>2022</td>\n",
       "      <td>Has good size and length for his position, sta...</td>\n",
       "      <td>For all of his offensive gifts, still has room...</td>\n",
       "      <td>99</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1631096</td>\n",
       "      <td>Chet Holmgren</td>\n",
       "      <td>2022</td>\n",
       "      <td>Extremely skilled frontcourt player who can in...</td>\n",
       "      <td>Lack of physical strength (195 lbs) remains hi...</td>\n",
       "      <td>97</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1631099</td>\n",
       "      <td>Keegan Murray</td>\n",
       "      <td>2022</td>\n",
       "      <td>A 6’8 225 frontcourt player with the frame, le...</td>\n",
       "      <td>Will have some questions about his true positi...</td>\n",
       "      <td>94</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1631093</td>\n",
       "      <td>Jaden Ivey</td>\n",
       "      <td>2022</td>\n",
       "      <td>An aggressive explosive, 6’4 200 lb combo guar...</td>\n",
       "      <td>Ivey’s hard charging energy and play style can...</td>\n",
       "      <td>98</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1631097</td>\n",
       "      <td>Bennedict Mathurin</td>\n",
       "      <td>2022</td>\n",
       "      <td>6’7 wing with tremendous size, maturity, explo...</td>\n",
       "      <td>The biggest hurdle for Mathurin at this point ...</td>\n",
       "      <td>97</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_id              player  season  \\\n",
       "0    1631094      Paolo Banchero    2022   \n",
       "1    1631096       Chet Holmgren    2022   \n",
       "2    1631099       Keegan Murray    2022   \n",
       "3    1631093          Jaden Ivey    2022   \n",
       "4    1631097  Bennedict Mathurin    2022   \n",
       "\n",
       "                                           strengths  \\\n",
       "0  Has good size and length for his position, sta...   \n",
       "1  Extremely skilled frontcourt player who can in...   \n",
       "2  A 6’8 225 frontcourt player with the frame, le...   \n",
       "3  An aggressive explosive, 6’4 200 lb combo guar...   \n",
       "4  6’7 wing with tremendous size, maturity, explo...   \n",
       "\n",
       "                                          weaknesses  overall  Athleticism  \\\n",
       "0  For all of his offensive gifts, still has room...       99            8   \n",
       "1  Lack of physical strength (195 lbs) remains hi...       97            8   \n",
       "2  Will have some questions about his true positi...       94            8   \n",
       "3  Ivey’s hard charging energy and play style can...       98            9   \n",
       "4  The biggest hurdle for Mathurin at this point ...       97            9   \n",
       "\n",
       "   Size  Defense  Strength  Quickness  Leadership  JumpShot  NBAReady  \\\n",
       "0     8        8         9          7           9         8         8   \n",
       "1     9        9         6          7           8         8         8   \n",
       "2     8        8         7          8           8         8         9   \n",
       "3     8        8         9          9           8         7         8   \n",
       "4     8        7         9          8           9         8         8   \n",
       "\n",
       "   Rebounding  Potential  PostSkills  Intangibles  BallHandling  Passing  \n",
       "0         9.0          8         8.0            9           NaN      NaN  \n",
       "1         9.0          9         8.0            8           NaN      NaN  \n",
       "2         NaN          7         NaN            9           7.0      7.0  \n",
       "3         NaN          9         NaN            8           7.0      8.0  \n",
       "4         NaN          9         NaN            8           7.0      7.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_cols = ['PERSON_ID','PLAYER_NAME','SEASON','strengths','weaknesses', 'overall','Athleticism','Size','Defense','Strength','Quickness',\n",
    "    'Leadership','JumpShot','NBAReady','Rebounding', 'Potential','PostSkills','Intangibles','BallHandling','Passing']\n",
    "rename_dict = {'PERSON_ID':'person_id','PLAYER_NAME':'player','SEASON':'season'}\n",
    "df = pd.merge(alltimedraft_df, draftnet_df, on='player', how='inner')[keep_cols]\n",
    "df.rename(rename_dict, axis=1, inplace=True)\n",
    "df = df.loc[df.season >= 2006]\n",
    "df = df.dropna(subset=['strengths'])\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in the all star information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "allstar_f = '../data/nba_allstar_all.csv'\n",
    "allstar_df = pd.read_csv(allstar_f)\n",
    "allstar_df = allstar_df.loc[allstar_df.year >= 2001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "all_star_indicator = []\n",
    "all_star_first_year = []\n",
    "for index, row in df.iterrows():\n",
    "    if row['player'] in allstar_df['Player'].values:\n",
    "        all_star_indicator.append(1)\n",
    "        player_allstar = allstar_df.loc[allstar_df['Player'] == row['player']]\n",
    "        year_min = player_allstar.year.min()\n",
    "        allstar_player_year = year_min - row['season']\n",
    "        all_star_first_year.append(allstar_player_year)\n",
    "    else:\n",
    "        all_star_indicator.append(0)\n",
    "        all_star_first_year.append(np.nan)\n",
    "df['allstar_bool'] = all_star_indicator\n",
    "df['allstar_first_year'] = all_star_first_year\n",
    "df['within7'] = (df.allstar_first_year <= 7).astype(int)\n",
    "df['within5'] = (df.allstar_first_year <= 5).astype(int)\n",
    "df.drop_duplicates(subset='player', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nlp feature extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "within 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Andy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Andy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Removing Punctuation\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    \n",
    "    # Removing Stop Words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Joining tokens back into a single text\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get names of 2023 mock draftees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "draft_2023_url = 'https://www.nbadraft.net/nba-mock-drafts/'\n",
    "response = requests.get(draft_2023_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "table = soup.find('table', id='nba_mock_consensus_table')\n",
    "df2023 = pd.read_html(str(table))[0]\n",
    "player_2023_list = []\n",
    "for player_name in df2023.Player:\n",
    "    player_2023_list.append(player_name.lower().replace(' ','-'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe containing the merged df and the 2023 mock draftees called all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine input data and 2023 data temporarily to run all through vectorizer\n",
    "all_df = pd.concat([df, draftnet_df.loc[draftnet_df.player.isin(player_2023_list)]])\n",
    "all_df['text'] = all_df['strengths'] + ' ' + all_df['weaknesses']\n",
    "all_df['text'] = all_df['text'].apply(preprocess_text)\n",
    "all_df = all_df.reset_index(drop=True)\n",
    "\n",
    "# apply NLP vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust the max_features parameter\n",
    "input_cols = ['overall','Athleticism','Size','Defense','Strength','Quickness', 'Leadership','JumpShot','NBAReady']\n",
    "X = vectorizer.fit_transform(all_df['text'])\n",
    "\n",
    "# combine vectorized array and the other input columns\n",
    "X = pd.concat([pd.DataFrame(X.toarray()), all_df[input_cols]], axis=1)\n",
    "X.columns = X.columns.astype(str) # convert to all string names\n",
    "# inds = np.where(all_df['draft_year'] == '2023')[0]\n",
    "# X_2023 = X[inds]\n",
    "# X = X[all_df['draft_year'] != '2023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 7\n",
    "if n == 5:\n",
    "    mask = (all_df.within5 == 1) | (all_df.season <= 2018)\n",
    "    # data = df.loc[(df.within5 == 1) | (df.season <= 2018)]\n",
    "else:\n",
    "    mask = (all_df.within7 == 1) | (all_df.season <= 2016)\n",
    "    # data = df.loc[(df.within7 == 1) | (df.season <= 2016)]\n",
    "\n",
    "# mask = mask & (all_df.season != 2015)\n",
    "# data['text'] = data['strengths'] + ' ' + data['weaknesses']\n",
    "# data['text'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "# vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust the max_features parameter\n",
    "# X = vectorizer.fit_transform(data['text'])\n",
    "X_rest = X[mask]\n",
    "y = all_df[mask]['within7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andy\\anaconda3\\envs\\nba-stats\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Model Training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rest, y, test_size=0.2, random_state=42, stratify=y)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.8709677419354839\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Model Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andy\\anaconda3\\envs\\nba-stats\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Andy\\anaconda3\\envs\\nba-stats\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Andy\\anaconda3\\envs\\nba-stats\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Andy\\anaconda3\\envs\\nba-stats\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Andy\\anaconda3\\envs\\nba-stats\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Andy\\anaconda3\\envs\\nba-stats\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Andy\\anaconda3\\envs\\nba-stats\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Andy\\anaconda3\\envs\\nba-stats\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Andy\\anaconda3\\envs\\nba-stats\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Andy\\anaconda3\\envs\\nba-stats\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: [0.91935484 0.77419355 0.90322581 0.87096774 0.87096774 0.91803279]\n",
      "precision: [0. 0. 0. 0. 0. 0.]\n",
      "recall: [0. 0. 0. 0. 0. 0.]\n",
      "f1: [0. 0. 0. 0. 0. 0.]\n",
      "roc_auc: [0.63508772 0.58928571 0.45238095 0.5787037  0.65972222 0.575     ]\n",
      "neg_log_loss: [-0.27296492 -0.58774047 -0.35383363 -0.3909283  -0.35983756 -0.29634134]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andy\\anaconda3\\envs\\nba-stats\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Andy\\anaconda3\\envs\\nba-stats\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_validate\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=2)\n",
    "scoring = ['accuracy','precision','recall','f1','roc_auc','neg_log_loss']\n",
    "model = LogisticRegression()\n",
    "scores = cross_validate(model, X_train, y_train, cv=kf, scoring=scoring)\n",
    "\n",
    "for metric in scoring:\n",
    "    metric_scores = scores[f'test_{metric}']\n",
    "    print(f'{metric}: {metric_scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andy\\anaconda3\\envs\\nba-stats\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "40 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Andy\\anaconda3\\envs\\nba-stats\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Andy\\anaconda3\\envs\\nba-stats\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\Andy\\anaconda3\\envs\\nba-stats\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Andy\\anaconda3\\envs\\nba-stats\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of LogisticRegression must be an instance of 'dict', a str among {'balanced'} or None. Got array([0.57076923, 4.0326087 ]) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Andy\\anaconda3\\envs\\nba-stats\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.87333333 0.87333333        nan        nan 0.88144144 0.87333333\n",
      "        nan        nan 0.88144144 0.87333333        nan        nan\n",
      " 0.88144144 0.87333333        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'C': 10, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score:  0.8814414414414415\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [5, 10, 15, 20],\n",
    "    'penalty': ['l1','l2'],\n",
    "    'solver': ['liblinear'],\n",
    "    'class_weight': [None, class_weights],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "model = LogisticRegression()\n",
    "grid_search = GridSearchCV(model, param_grid, cv=kf, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Best hyperparameters: ', grid_search.best_params_)\n",
    "print('Best Score: ', grid_search.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try it out on this year's draft class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, max_iter=1000, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, max_iter=1000, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, max_iter=1000, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = draftnet_df.loc[draftnet_df.draft_year == '2023']\n",
    "# data['text'] = data['strengths'] + ' ' + data['weaknesses']\n",
    "# data['text'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "# mask = all_df['draft_year'] == '2023'\n",
    "# inds = np.where(all_df['draft_year'] == '2023')[0]\n",
    "# X_2023 = X[mask]\n",
    "\n",
    "# vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust the max_features parameter\n",
    "# tmp_X = vectorizer.fit_transform(data['text'])\n",
    "# tmp_X = \n",
    "\n",
    "model = LogisticRegression(**grid_search.best_params_)\n",
    "model.fit(X_rest, y)\n",
    "# y_pred = model.predict(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = all_df['season'] == 2015\n",
    "# mask = all_df['draft_year'] == '2023'\n",
    "mask = all_df.player.isin(player_2023_list)\n",
    "X_2023 = X[mask]\n",
    "y_pred_prob = model.predict_proba(X_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andy\\AppData\\Local\\Temp\\ipykernel_14976\\443112442.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2023['allstar_prob'] = [x[1] * 100 for x in y_pred_prob]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>allstar_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>amen-thompson</td>\n",
       "      <td>12.726752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>anthony-black</td>\n",
       "      <td>34.590731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>ausar-thompson</td>\n",
       "      <td>1.529834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>bilal-coulibaly</td>\n",
       "      <td>36.146948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>bobi-klintman</td>\n",
       "      <td>16.676989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              player  allstar_prob\n",
       "713    amen-thompson     12.726752\n",
       "714    anthony-black     34.590731\n",
       "715   ausar-thompson      1.529834\n",
       "716  bilal-coulibaly     36.146948\n",
       "717    bobi-klintman     16.676989"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2023 = all_df[mask]\n",
    "df_2023['allstar_prob'] = [x[1] * 100 for x in y_pred_prob]\n",
    "df_2023 = df_2023[['player','allstar_prob']]\n",
    "df_2023.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba-stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
